{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Testing\n",
    "\n",
    "This tutorial covers different methods of comparing data to given gate-set models.  This is distinct from gate set *tomography*, which finds the best-fitting model for a data set within a space of considered gate-set models.  You might use this as a tool alongside or separate from GST.  Perhaps you suspect that a given noisy gate-set model is compatible with your data - model *testing* is the way to find out. Because there is no optimization involved, model testing requires much less time than GST does.\n",
    "\n",
    "## Setup\n",
    "First, after some usual imports, we'll create some test data based on a depolarized and rotated version of a standard 1-qubit gate set consisting of $I$ (the identity), $X(\\pi/2)$ and $Y(\\pi/2)$ gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import pygsti\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from pygsti.construction import std1Q_XYI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "datagen_gateset = std1Q_XYI.gs_target.depolarize(gate_noise=0.05, spam_noise=0.1).rotate((0.05,0,0.03))\n",
    "exp_list = pygsti.construction.make_lsgst_experiment_list(\n",
    "    std1Q_XYI.gs_target, std1Q_XYI.prepStrs, std1Q_XYI.effectStrs,\n",
    "    std1Q_XYI.germs, [1,2,4,8,16,32,64])\n",
    "ds = pygsti.construction.generate_fake_data(datagen_gateset, exp_list, nSamples=1000,\n",
    "                                             sampleError='binomial', seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 1: Construct a test model\n",
    "After we have some data, the first step is creating a model or models that we want to test.  This just means creating a `GateSet` object containing the gates and spam lables found in the data set.  We'll create several gate sets that are meant to look like guesses (some including more types of noise) of the true underlying gate set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gs_target = std1Q_XYI.gs_target\n",
    "test_model1 = gs_target.copy()\n",
    "test_model2 = gs_target.depolarize(gate_noise=0.07, spam_noise=0.07)\n",
    "test_model3 = gs_target.depolarize(gate_noise=0.07, spam_noise=0.07).rotate( (0.02,0.02,0.02) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 2: Test it!\n",
    "There are three different ways to test a model.  Note that in each case the default behavior (and the only behavior demonstrated here) is to **never gauge-optimize the test `GateSet`**.  Whenever gauge-optimized versions of an `Estimate` are useful for comparisons with other estimates *copies* of the test `GateSet` are used *without* actually performing any true modification of the `GateSet`.\n",
    "\n",
    "### Method1: `do_model_test`\n",
    "First, you can do it \"from scratch\" by calling `do_model_test`, which has a similar signature as `do_long_sequence_gst` and folows its pattern of returning a `Results` object.  The \"estimateLabel\" advanced option, which names the `Estimate` within the returned `Results` object, can be particularly useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gate Sequence Creation ---\n",
      "   2122 sequences created\n",
      "   Dataset has 2122 entries: 2122 utilized, 0 requested sequences were missing\n",
      "  -- Adding Gauge Optimized (go0) --\n",
      "--- Gate Sequence Creation ---\n",
      "   2122 sequences created\n",
      "   Dataset has 2122 entries: 2122 utilized, 0 requested sequences were missing\n",
      "  -- Adding Gauge Optimized (go0) --\n",
      "--- Gate Sequence Creation ---\n",
      "   2122 sequences created\n",
      "   Dataset has 2122 entries: 2122 utilized, 0 requested sequences were missing\n",
      "  -- Adding Gauge Optimized (go0) --\n"
     ]
    }
   ],
   "source": [
    "# creates a Results object with a \"default\" estimate\n",
    "results = pygsti.do_model_test(test_model1, ds, gs_target, \n",
    "                               std1Q_XYI.prepStrs, std1Q_XYI.effectStrs, std1Q_XYI.germs,\n",
    "                               [1,2,4,8,16,32,64]) \n",
    "\n",
    "# creates a Results object with a \"default2\" estimate\n",
    "results2 = pygsti.do_model_test(test_model2, ds, gs_target, \n",
    "                               std1Q_XYI.prepStrs, std1Q_XYI.effectStrs, std1Q_XYI.germs,\n",
    "                               [1,2,4,8,16,32,64], advancedOptions={'estimateLabel': 'default2'}) \n",
    "\n",
    "# creates a Results object with a \"default3\" estimate\n",
    "results3 = pygsti.do_model_test(test_model3, ds, gs_target, \n",
    "                               std1Q_XYI.prepStrs, std1Q_XYI.effectStrs, std1Q_XYI.germs,\n",
    "                               [1,2,4,8,16,32,64], advancedOptions={'estimateLabel': 'default3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Like any other set of `Results` objects which share the same `DataSet` and gate sequences, we can collect all of these estimates into a single `Results` object and easily make a report containing all three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "*** Generating tables ***\n",
      "*** Generating plots ***\n",
      "*** Merging into template file ***\n",
      "Output written to tutorial_files/modeltest_report directory\n",
      "Opening tutorial_files/modeltest_report/main.html...\n",
      "*** Report Generation Complete!  Total time 163.613s ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygsti.report.workspace.Workspace at 0x10c8adf28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.add_estimates(results2)\n",
    "results.add_estimates(results3)\n",
    "\n",
    "pygsti.report.create_standard_report(results, \"tutorial_files/modeltest_report\", \n",
    "                                     title=\"Model Test Example Report\",\n",
    "                                     auto_open=True, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Method 2: `add_model_test`\n",
    "Alternatively, you can add a model-to-test to an existing `Results` object.  This is convenient when running GST via `do_long_sequence_gst` or `do_stdpractice_gst` has left you with a `Results` object and you also want to see how well a hand-picked model fares.  Since the `Results` object already contains a `DataSet` and list of sequences, all you need to do is provide a `GateSet`.  This is accomplished using the `add_model_test` method of a `Results` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Std Practice:  Iter 1 of 3  (TP) --: \n",
      "  --- Gate Sequence Creation ---\n",
      "  --- LGST ---\n",
      "  --- Iterative MLGST: [##################################################] 100.0%  2122 gate strings ---\n",
      "  Iterative MLGST Total Time: 6.3s\n",
      "  -- Performing 'single' gauge optimization on TP estimate --\n",
      "-- Std Practice:  Iter 2 of 3  (CPTP) --: \n",
      "  --- Gate Sequence Creation ---\n",
      "  --- Iterative MLGST: [##################################################] 100.0%  2122 gate strings ---\n",
      "  Iterative MLGST Total Time: 8.8s\n",
      "  -- Performing 'single' gauge optimization on CPTP estimate --\n",
      "-- Std Practice:  Iter 3 of 3  (Target) --: \n",
      "  --- Gate Sequence Creation ---\n",
      "  -- Performing 'single' gauge optimization on Target estimate --\n",
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "*** Generating tables ***\n",
      "*** Generating plots ***\n",
      "*** Merging into template file ***\n",
      "Output written to tutorial_files/gstwithtest_report1 directory\n",
      "Opening tutorial_files/gstwithtest_report1/main.html...\n",
      "*** Report Generation Complete!  Total time 211.786s ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygsti.report.workspace.Workspace at 0x10d865be0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create some GST results using do_stdpractice_gst\n",
    "gst_results = pygsti.do_stdpractice_gst(ds, gs_target, \n",
    "                                        std1Q_XYI.prepStrs, std1Q_XYI.effectStrs,\n",
    "                                        std1Q_XYI.germs, [1,2,4,8,16,32,64])\n",
    "\n",
    "#Add a model to test\n",
    "gst_results.add_model_test(gs_target, test_model3, estimate_key='MyModel3')\n",
    "\n",
    "#Create a report to see that we've added an estimate labeled \"MyModel3\"\n",
    "pygsti.report.create_standard_report(gst_results, \"tutorial_files/gstwithtest_report1\", \n",
    "                                     title=\"GST with Model Test Example Report 1\",\n",
    "                                     auto_open=True, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Method 3: `modelToTest` argument\n",
    "Finally, yet another way to perform model testing alongside GST is by using the `modelsToTest` argument of `do_stdpractice_gst`.  This essentially combines calls to `do_stdpractice_gst` and `Results.add_model_test` (demonstrated above) with the added control of being able to specify the ordering of the estimates via the `modes` argument.  To important remarks are in order:\n",
    "\n",
    "1. You *must* specify the names (keys of the `modelsToTest` argument) of your test models in the comma-delimited string that is the `modes` argument.  Just giving a dictionary of `GateSet`s as `modelsToTest` will not automatically test those models in the returned `Results` object.\n",
    "\n",
    "2. You don't actually need to run any GST modes, and can use `do_stdpractice_gst` in this way to in one call create a single `Results` object containing multiple model tests, with estimate names that you specify.  Thus `do_stdpractice_gst` can replace the multiple `do_model_test` calls (with \"estimateLabel\" advanced options) followed by collecting the estimates using `Results.add_estimates` demonstrated under \"Method 1\" above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Std Practice:  Iter 1 of 4  (TP) --: \n",
      "  --- Gate Sequence Creation ---\n",
      "  --- LGST ---\n",
      "  --- Iterative MLGST: [##################################################] 100.0%  2122 gate strings ---\n",
      "  Iterative MLGST Total Time: 6.1s\n",
      "  -- Performing 'single' gauge optimization on TP estimate --\n",
      "-- Std Practice:  Iter 2 of 4  (Test2) --: \n",
      "  --- Gate Sequence Creation ---\n",
      "  -- Performing 'single' gauge optimization on Test2 estimate --\n",
      "-- Std Practice:  Iter 3 of 4  (Test3) --: \n",
      "  --- Gate Sequence Creation ---\n",
      "  -- Performing 'single' gauge optimization on Test3 estimate --\n",
      "-- Std Practice:  Iter 4 of 4  (Target) --: \n",
      "  --- Gate Sequence Creation ---\n",
      "  -- Performing 'single' gauge optimization on Target estimate --\n",
      "*** Creating workspace ***\n",
      "*** Generating switchboard ***\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "Found standard clifford compilation from std1Q_XYI\n",
      "*** Generating tables ***\n",
      "*** Generating plots ***\n",
      "*** Merging into template file ***\n",
      "Output written to tutorial_files/gstwithtest_report2 directory\n",
      "Opening tutorial_files/gstwithtest_report2/main.html...\n",
      "*** Report Generation Complete!  Total time 224.609s ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygsti.report.workspace.Workspace at 0x10f5520b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gst_results = pygsti.do_stdpractice_gst(ds, gs_target, std1Q_XYI.prepStrs, std1Q_XYI.effectStrs, std1Q_XYI.germs,\n",
    "                                       [1,2,4,8,16,32,64], modes=\"TP,Test2,Test3,Target\", # You MUST \n",
    "                                       modelsToTest={'Test2': test_model2, 'Test3': test_model3})\n",
    "\n",
    "pygsti.report.create_standard_report(gst_results, \"tutorial_files/gstwithtest_report2\", \n",
    "                                     title=\"GST with Model Test Example Report 2\",\n",
    "                                     auto_open=True, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
